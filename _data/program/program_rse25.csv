ID,speaker,affiliation,position,bio,title,abstract,topic,session,day,start_time,duration,end_time
,,,,,,,Check in,Tu.Ch,Tuesday 9th,08:30,30,09:00
,Mikkel Baun Kjærgaard,SDU,,,Welcome Talk / SDU Keynote,,Welcome talk,Tu.W,Tuesday 9th,09:00,45,09:45
,,,,,,,Coffee Break,Tu.CB1,Tuesday 9th,09:45,15,10:00
,Mirgita Frasheri,Aarhus University,,,Building a Digital Twin for the Desktop Robotti,"This talk will provide an overview of the current state of the Digital Twin built for a mobile robot, specifically the Desktop Robotti, that is a prototype of an agricultural robot produced by the Danish company AgroIntelli. We will present our results, and share challenges and lessons learned.",Sessions & Discussions,Tu1,Tuesday 9th,10:00,20,10:20
,Andreas Wiedholz,XITASO GmbH,,,Self-adaptive systems based on ROS2: Current research plan,"Self adaptive systems enable modifications of a system's behavior at runtime which leads to improved abilities to react to changes in the environment and failures of the system. Human involvement necessitates systems that adapt to actions while maintaining transparent decision-making. With more humans collaborating with robots over the last years, applying the concept of self-adaptive systems in the robotic domain is getting more attention but is still in the earlier stages of research. Currently, self-adaptive systems applied to robotic use cases, focus rather on the task being executed successfully and maintaining a high Quality of Service. Additionally to these aspects, my research aims to monitor the system health of ROS nodes, ensuring robust operational reliability in safety critical applications. Building upon that, I want to investigate how to make the decision making process of the self-adaptive system more transparent to humans interacting with this system, increasing their acceptance and trust for these systems. By introducing a higher robustness and advanced transparency into self-adaptive systems , my research aims to foster greater user trust and acceptance, paving the way for more seamless human-robot collaboration.",Sessions & Discussions,Tu1,Tuesday 9th,10:20,20,10:40
,Till Schallau,TU Dortmund University,,,STARS: Classification of Scenarios and Checking of Functional Requirements of Automated Robotic Systems,"Automated robotic systems are designed to operate correctly in complex environments, making their testing a critical aspect of development. However, statistically systematic testing is infeasible due to the immense number of test cases required. Early-stage validation of these systems often relies on scenario-based testing combined with simulations. While simulations provide controlled environments for testing, real-world deployments can reveal unforeseen situations and scenarios that were not considered during development.

To address this challenge, it is crucial to detect encountered scenarios in real-world data and calculate the extent to which all possible scenarios are covered. Additionally, verifying the correct execution of system functionalities under various conditions is essential for ensuring safety and reliability.

Our approach leverages tree-based scenario classification (TSC) combined with temporal logics to systematically analyze recorded data from automated robotic systems. The hierarchical TSC structure organizes features into semantic layers, enabling efficient classification of observed scenarios while reducing combinatorial complexity. By computing metrics such as scenario class coverage, feature occurrence distributions, and identifying missing feature combinations, our method provides detailed insights into gaps in tested and observed scenarios. Furthermore, we integrate requirement monitoring through formalized predicates to validate system behavior against predefined functional requirements.

This framework has been applied successfully both in simulation environments - such as CARLA - and using real-world experimental setups involving scaled vehicle platooning controllers. Our method not only identifies failed requirements but also traces them back to specific triggering conditions within classified scenarios. This enables targeted debugging and refinement of the system behavior while enhancing dependability across diverse operational design domains (ODDs). By bridging simulated and real-world analyses, our approach contributes significantly to improving robustness and safety assurance for autonomous systems operating across dynamic environments.",Sessions & Discussions,Tu1,Tuesday 9th,10:40,20,11:00
,Kevin Hermann,Ruhr University Bochum,,,A Taxonomy of Functional Security Features and How They Can Be Located,"Security must be considered in almost every software system, including cyber-physical systems. Unfortunately, selecting and implementing security features remains a challenge due to the wide variety of security threats and possible countermeasures. While security standards are intended to help developers, they are usually too abstract and vague to help implementing security features for robotic systems, or they merely help configuring such. A resource that describes security features at an abstraction level that lies between high-level (i.e., rather too general) and low-level (i.e., rather too specific) security standards could facilitate secure systems development. This resource should support the selection of appropriate security features to achieve high-level security goals, allow easy retrieval of relevant low-level details, and provide pointers to suitable ways to realize the security features. To realize security features, developers typically use external security libraries or frameworks, to minimize implementation mistakes. Even when using libraries, developers still make mistakes when writing code to integrate them, often resulting in security vulnerabilities. When security incidents occur or the system needs to be audited or maintained, it is essential to know what security features have been implemented and, more importantly, where they are located. This task, commonly referred to as feature location, is often tedious and error-prone. While dedicated feature location techniques exist, they require significant manual effort or adherence to strict development processes, preventing their use. Therefore, we have to support long-term tracking of implemented security features.

We present a study of security features presented in the literature and their coverage in popular security frameworks. We contribute (1) a taxonomy of 68 functional implementation-level security features including a mapping to widely used security standards, (2) an examination of 21 popular security frameworks concerning which of these security features they provide, and (3) a discussion on the representation of security features in source code. Our taxonomy aims to aid developers in selecting appropriate security features and security frameworks, as well as relating them to security standards when they need to choose and implement security features for a software system.",Sessions & Discussions,Tu1,Tuesday 9th,11:00,20,11:20
,,,,,,,Lunch,Tu.Lu,Tuesday 9th,11:20,70,12:30
,,,,,,,I40Lab Tour,Tu.T,Tuesday 9th,12:30,120,14:30
,,,,,,,Coffee Break,Tu.CB2,Tuesday 9th,14:30,15,14:45
,Nils Chur,Ruhr University Bochum,,,Beyond the Control Equations: An Artifact Study of Implementation Quality in Robot Control Software,"Robotic systems tightly integrate software with physical hardware, and often operate in safety-critical domains such as transportation, healthcare, and manufacturing. A key component in these systems is the controller, a software component responsible for managing hardware behavior to ensure properties like stability and robustness. While control theory provides guarantees about system behavior, the practical implementation of controllers in software introduces complexities that are often overlooked. Control theory typically assumes that controllers operate in a continuous domain, whereas software operates in a discrete domain, requiring careful discretization to maintain theoretical guarantees. Despite extensive research on control theory and controller modeling, little attention has been given to the actual implementation of controllers and how their theoretical guarantees are ensured in real-world software systems.

	In this study, we investigate 184 real-world controller implementations in open-source robot software to bridge this gap. We examine the application of these controllers, their implementation characteristics, and the testing techniques employed to ensure correctness. Our analysis reveals that many controller implementations handle discretization in an ad hoc manner, leading to potential issues with real-time reliability. Additionally, challenges such as timing inconsistencies, lack of proper error handling, and inadequate consideration of real-time constraints further complicate implementations. Furthermore, testing practices are superficial and often lack systematic verification of theoretical guarantees, leaving possible inconsistencies between expected and actual system behavior. Our findings highlight the need for improved implementation guidelines and rigorous verification techniques to ensure the reliability and safety of robotic controllers in practice.",Sessions & Discussions,Tu2,Tuesday 9th,14:45,20,15:05
,Felix Reuter,University of Southern Denmark,,,Simulation and Analysis of Vision-Based Welding Operations of Micro Panels in Shipbuilding,"As part of the ShipWeldFlow project, two robot programming techniques are combined to improve the welding of so called micro panels, a common type of subassembly in shipbuilding. While CAD-based programming offers reliable, easy to simulate robot programs, it also requires more human interaction and a system for data exchange between the engineering and production departments. Vision-based programming on the other hand is simpler and more flexible since robot programs are generated on the fly, but the procedure is less predictable.

In this talk I will present a simulation-based approach that aims to increase the reliability of vision-based welding robots by executing the process steps on a digital twin beforehand. When combining this with planning information from a ship design database intended for CAD-based programming, the behavior of the vision-based approach can be compared and validated.
To provide realistic sensor and robot simulations, a co-simulation approach is implemented in a visual programming interface. The created zero-programming workflow allows for automatic processing of whole ship blocks. The operator is provided with automatic reports, as well as data for manual reviewing and more detailed planning of the production scheduling.",Sessions & Discussions,Tu2,Tuesday 9th,15:05,20,15:25
,Ricardo Diniz Caldas,Gran Sasso Science Institute,,,Runtime Verification and Field-based Testing for ROS-based Robotic Systems,"Robotic systems are becoming pervasive and adopted in increasingly many domains, such as manufacturing, healthcare, and space exploration. To this end, engineering software has emerged as a crucial discipline for building maintainable and reusable robotic systems. The field of robotics software engineering research has received increasing attention, fostering autonomy as a fundamental goal. However, robotics developers are still challenged trying to achieve this goal given that simulation is not able to deliver solutions to realistically emulate real-world phenomena. Robots also need to operate in unpredictable and uncontrollable environments, which require safe and trustworthy self-adaptation capabilities implemented in software. Typical techniques to address the challenges are runtime verification, field-based testing, and mitigation techniques that enable fail-safe solutions. However, there is no clear guidance to architect ROS-based systems to enable and facilitate runtime verification and field-based testing. This paper aims to fill in this gap by providing guidelines that can help developers and quality assurance (QA) teams when developing, verifying or testing their robots in the field. These guidelines are carefully tailored to address the challenges and requirements of testing robotics systems in real-world scenarios. We conducted (i) a literature review on studies addressing runtime verification and field-based testing for robotic systems, (ii)  mined ROS-based applications repositories, and (iii) validated the applicability, clarity, and usefulness via two questionnaires with 55 answers overall. We contribute 20 guidelines: 8 for developers and 12 for QA teams formulated for researchers and practitioners in robotic software engineering. Finally, we map our guidelines to open challenges thus far in runtime verification and field-based testing for ROS-based systems and, we outline promising research directions in the field.",Sessions & Discussions,Tu2,Tuesday 9th,15:25,20,15:45
,Ola Rønning,University of Copenhagen,,,Real-Time Bayesian Filtering for Pose Estimation with Stein Mixtures,"Robots operating in unstructured environments must reliably determine their pose (position and orientation) from diverse
sensors such as lidar, radar, sonar, and cameras—much like humans rely on sight, hearing, and touch. Achieving high
accuracy and real-time performance is critical for navigation and mapping. However, in real-world modeling, accuracy
and uncertainty are inherently in tension. Traditional approaches like Kalman and particle filters can quantify
uncertainty but often rely on assumptions about sensor errors and dimensionality that undermine both accuracy and
real-time feasibility. Deep-learning-based methods, while efficient and accurate, can become dangerously overconfident
in unexpected scenarios. As an alternative, Stein mixture inference strikes a balance between accuracy and uncertainty,
and it has already demonstrated scalability for six-dimensional problems in other domains—precisely the dimensionality
of a standard robot pose. Building on this, we propose a transport map approach to Bayesian filtering using Stein mixture
inference to propagate the current pose belief. Although constructing a transport map requires solving an optimization
problem at every sensor reading, we emphasize rapid convergence at low cost to ensure real-time performance. By
effectively managing both uncertainty and speed, this approach aims to improve the safety and reliability of robotic
navigation and mapping in dynamic, unpredictable environments.
",Sessions & Discussions,Tu2,Tuesday 9th,15:45,20,16:05
,,,,,,,Coffee Break,Tu.CB3,Tuesday 9th,16:05,15,16:20
,Argentina Ortega,University of Bremen,,,TBD,,Sessions & Discussions,Tu3,Tuesday 9th,16:20,20,16:40
,Sune Lundø Sørensen,SDU Software Engineering,,,World Modeling for TDB,,Sessions & Discussions,Tu3,Tuesday 9th,16:40,20,17:00
,,,,,,,Round Table Discussions,Tu.RT,Tuesday 9th,17:00,30,17:30
,,,,,Keynote 1: Academia vs Industry – insights from Universal Robots,,Keynote,We.K2,Wednesday 10th,13:15,45,14:00
,,,,,,"Turistbusholdepladsen Dannebrogsgade 5, 5000 Odense C.",Airport Transportation,We.AT,Wednesday 10th,08:30,30,09:00
,,,,,,,Welcome / Overview,We.W,Wednesday 10th,09:00,20,09:20
,Ulrik Pagh Schultz Lundquist,SDU UAS,,,Keynote: SDU UAS,,Keynote,We.K1,Wednesday 10th,09:20,30,09:50
,,,,,,,Tour,We.T1,Wednesday 10th,09:50,20,10:10
,,,,,,,Coffee Break,We.CB1,Wednesday 10th,10:10,30,10:40
,Marco Autili,University of L'Aquila,,,Adaptive Coordination of Multi Robot Systems: addressing Uncertainty while embracing Ethical-awareness,"Multi Robot Systems (MRSs) are increasingly employed to tackle complex tasks in diverse fields such as healthcare, logistics, and infrastructure maintenance. These systems are typically guided by mission specifications that define the objectives they must reach. Correct coordination among robots is critical to achieving the mission goals. However, the unpredictable and rapidly changing nature of real-world environments together with emerging mission-level needs, which may dynamically introduce unforeseen behaviors that cannot be completely anticipated at design time, introduce uncertainty, making coordination particularly challenging. Moreover, in recent years, there has been a significant rise in the development of autonomous robots designed to assist humans in shared spaces. Increasingly often, these robots are required to act on behalf of humans, autonomously making decisions from them, so it becomes crucial to dynamically align their decision-making process with the ethical preferences of those users. Consequently, the realization of MRSs requires a shift from traditional, static mission specification and planning to a dynamic and reconfigurable mission specification that allows MRSs to suitably coordinate their behavior with respect to the actual runtime environmental conditions, emerging needs, and ethical preferences of users. This talk is about the major challenges that MRSs must face concerning the correct coordination of the involved robots, possibly among multiple missions, by considering uncertainty and ethical aspects.",Sessions & Discussions,We1,Wednesday 10th,10:40,20,11:00
,Mahsa Varshosaz,IT University of Copenhagen,,,Monitoring Safety and Reliability of Underwater Robots: A Case Study,"Exploring oceans and monitoring underwater infrastructure is becoming ever more important. Autonomous underwater robots are used to operate tasks in hostile and dangerous underwater environment without human intervention. To achieve their full potential, the safety and reliability of their behavior is crucial, as their malfunction or loss can lead to catastrophic consequences. In this paper, we provide a case study involving the simulation of underwater robots and the analysis of a set of safety properties of the robots using runtime monitoring. We demonstrate the challenges in checking such properties in this context.
Exploring oceans and monitoring underwater infrastructure is becoming ever more important. Autonomous underwater robots are used to operate tasks in hostile and dangerous underwater environment without human intervention. To achieve their full potential, the safety and reliability of their behavior is crucial, as their malfunction or loss can lead to catastrophic consequences. In this talk, I will present the preliminary results on monitoring some of the safety properties of underwater robots in simulation.",Sessions & Discussions,We1,Wednesday 10th,11:00,20,11:20
,,,,,,,Round Table Discussions,We.RT1,Wednesday 10th,11:20,30,11:50
,,,,,,,Lunch,We.Lu,Wednesday 10th,11:50,25,12:15
,,,,,,,UR/MIR Transportation,We.T2,Wednesday 10th,12:20,40,13:00
,,,,,,,Executive Welcome,We.EW,Wednesday 10th,13:00,15,13:15
,,,,,,"Keynote 1: Academia vs Industry – insights from Universal Robots",,Keynote,We.K2,Wednesday 10th,13:15,45,14:00
,,,,,"Keynote 2: Odense Robotics",,Keynote,We.K3,Wednesday 10th,14:00,45,14:45
,,,,,,,Coffee Break and meet the experts from UR,We.CB2,Wednesday 10th,14:45,30,15:15
,,,,,,,Showroom and Quality gate tour,We.T3,Wednesday 10th,15:15,45,16:00
,,,,,,,Networking,We.N,Wednesday 10th,16:00,30,16:30
,,,,,,,Transportation back to city center,We.T4,Wednesday 10th,16:30,20,16:50
,,,,,,,Dinner,We.Di,Wednesday 10th,18:00,,,
,Laura Weihl,IT University of Copenhagen,,,Gaussian Splats as Test Video Generators for Visual Loop Closure in Autonomous Systems,"Recognizing previously visited locations based only on monocular camera input remains a critical challenge in visual SLAM, particularly for autonomous underwater vehicles (AUVs) operating in low-contrast, repetitive feature environments. False loop closure detections (LCD) can severely corrupt the learned map which makes vSLAM particularly vulnerable to underwater environments exhibiting these visual properties. In this work, we propose using 3D Gaussian Splatting (3DGS) to generate targeted synthetic test videos for evaluating LCD performance. By training 3DGS models on real underwater footage and rendering looped camera trajectories at various training stages, we create controlled test data with varying scene fidelity. This enables systematic benchmarking of LCD methods under challenging visual conditions typical of underwater inspection tasks. Preliminary results show that scene quality improves with training steps, offering a valuable tool for robust LCD evaluation in vSLAM.",Sessions & Discussions,Th1,Thursday 11th,09:00,20,09:20
,Vicente Romeiro Moraes,Ruhr Universität Bochum,,,Property Specification and Verification for Behaviour Trees,"Robots are becoming an ever more present part in our daily lives and are increasingly intelligent and driven by software, data, and AI. Unfortunately, uncertainties about the environment and operating context are an inherent challenge faced by robotic software systems. Especially for robots that perform tasks in a human environment—a.k.a. service robots—require dependable and reliable software. This poses the challenge of developing software that is not only robust, but also adaptable to a dynamic runtime environment. As such, the software for service robots must be engineered to reliably achieve specific goals while yet be flexible enough to adapt when those goals become unattainable during operation.
This Research project focuses on the development of novel methods and tools for verifying the behavior of robotic software against defined properties. Specifically, inspired by formal methods, particularly temporal logics (e.g., LTL) and model checking, we aim to develop property specification languages that allow engineers to specify properties for correctness, robustness and adaptability that can be checked against contemporary behavior-specification methods in robotics – behavior trees.
The work will be embedded into Berger’s existing work on behavior trees, or more generally, behavior-specification techniques for robotic systems. It will also be related to work on robotic configuration being conducted by another PhD student of Berger’s research group.
We believe that the property specification and verification techniques will foster follow-up works in the research community extending the expressiveness of property specification and novel static verification techniques inspired by model checking.",Sessions & Discussions,Th1,Thursday 11th,09:20,20,09:40
,Diana Carolina Benjumea Hernandez,The University of Manchester,,,Instantiating an Architecture for Autonomous Robots in Highly Regulated Domains,"Deploying autonomous robots in highly regulated domains requires architectures that demonstrably ensure operational effectiveness and compliance with safety requirements. This work presents an architecture that integrates autonomous control systems with a safety oversight mechanism to address this challenge. The architecture consists of two key components: the Safety-Related Autonomous System (SRAS), which handles the robot's daily operations, and the Safety Instrumented Function (SIF), which provides independent safety oversight and reversionary control with formal guarantees. We demonstrate this architecture by implementing it on an AgileX Scout Mini robot performing an inspection task using Robot Operating System (ROS) and Simultaneous Localization and Mapping (SLAM). The SIF’s algorithm is designed as a Belief-Desire-Intention (BDI) agent, ensuring compliance with a critical safety requirement—maintaining a safe distance from obstacles. The implementation is tested in a Gazebo simulation of a nuclear waste storage scenario, with formal verification techniques used to validate that this safety constraint is adhered to. Our results show that the proposed architecture supports autonomous operation in safety-critical settings. We discuss the scalability of the approach, challenges in verifying safety requirements, and future directions for enhancing the architecture to address more complex safety constraints.",Sessions & Discussions,Th1,Thursday 11th,09:40,20,10:00
,Gianluca Filippone,Gran Sasso Science Institute,,,MULTI-3: Empowering Multi-Mission Multi-Robot and Multi-Instance Task Execution,"Multi-robot systems (MRSs) are gaining increasing interest as effective means for addressing complex tasks in various domains. This presentation focuses on three multiplicity problems MRSs are required to address to improve flexibility and resource utilization and reduce idle times or busy forms of waiting: (i) enabling multi-purpose robots to execute multiple missions at a time, (ii) modeling MRS missions with multi-instance tasks, i.e., tasks that need to be repeated for a number of locations or objects, and (iii) enabling dynamic task assignment to have more robust and resilient missions. MULTI-3 is a framework that allows the specification and execution of multiple missions (multi-missions) through a fleet of robots (multi-robots) that can execute multiple instances of the same task (multi-instance). It operates both at specification and at execution levels. At the specification level, it enables the definition of multiple missions, which can then be added or removed at runtime. At the execution level, the runtime support permits the adaptive coordination of the involved robots while dynamically switching across multiple missions and executing multi-instance tasks within them, further enhancing system resiliency and recoverability.",Sessions & Discussions,Th1,Thursday 11th,10:00,20,10:20
,,,,,,,Coffee Break,Th.CB1,Thursday 11th,10:20,15,10:35
,Taiga Suda and and Takashi Yoshimi,Shibaura Institute of Technology,,,Application and evaluation of model predictive control (MPC) to a polishing robot system,"Many polishing robots use PID control to control the position of the hand tool and the force applied to the workpiece. However, it takes time and effort to adjust the control parameters in order to process workpieces of various shapes and materials with high accuracy in a polishing robot, and the operator is required the experiences to properly adjust the PID control gains.
    In this study, we are aiming for realizing a polishing robot control system with high control performance while reducing the burden of adjusting PID control parameters by applying model predictive control (MPC). Conventional MPC requires an accurate model of the controlled object, but it is difficult to accurately model the physical phenomena in an actual robot system, and using a complex model increases the calculation load of the MPC. Therefore, we expressed the relationship between the position and force in the system in which the tool held by the robot is pressed against the workpiece using a simple spring model. Furthermore, we accurately modeled and incorporated response characteristics such as dead time in the robot controller. By applying MPC using our constructed model, we were able to improve the control performance while reducing the time required to adjust the control parameters of the polishing robot.
    We will report on the above efforts and the evaluation results of the constructed control system in our presentation.",Sessions & Discussions,Th2,Thursday 11th,10:35,20,10:55
,Thorsten Berger,Ruhr University Bochum,,,Teaching Autonomous Driving,"I will present our experiences and future plans on teaching autonomous vehicles, specifically the whole development process, architecture, testing, and also AI engineering practices needed to engineer complex autonomous systems.",Sessions & Discussions,Th2,Thursday 11th,10:55,20,11:15
,Gianluca Bardaro,Politecnico di Milano,,,Robot software in the era of large models,"In today’s robotics landscape, two distinct paradigms coexist. On one side are classical techniques grounded in control theory. These methods prioritize reliability, robustness, and predictability. They rely on well-established mathematical models, real-time control algorithms, and structured frameworks (such as ROS) to ensure that robots perform consistently and safely in controlled environments. For applications where safety and precision are the priority, these methods provide verifiable performance and are backed by empirical and theoretical validation. However, their major limitation is flexibility. When faced with unforeseen environmental changes or novel tasks, these systems require substantial human intervention or a complete redesign of the control strategy. This rigidity means that while classical approaches excel in stable, predictable conditions, they can be slow to adapt in dynamic or unstructured settings.
In parallel, a second stream of research focuses on end-to-end, data-driven methods. Leveraging recent advancements in deep reinforcement learning, transFformers, and large language models (LLMs), this approach learns behaviors directly from data. Such models have demonstrated impressive achievements, exhibiting remarkable flexibility and adaptability to varied and unanticipated scenarios. This paradigm allows robots to generalize from past experiences and quickly adapt to new tasks, which is especially useful in rapidly changing environments or when task specifications evolve. However, the data-driven approach comes with significant drawbacks. Collecting the vast amounts of data required for robust training in robotics is notoriously challenging, as real-world robotic interactions are both expensive and time-consuming to capture. Moreover, the computational power needed for training these models and deploying them in real-time on robots can be challenging, limiting their practical use in many embedded systems and safety-critical applications.
In this divided landscape, what is the role of software? Until now, software has been the fundamental enabler of robot autonomy, ranging from low-level functionalities to complex behaviors. Learned solutions are more flexible and adaptable, achieving results that are impossible to encode algorithmically. However, the downsides and limitations of such approaches cannot be ignored.
An interesting solution is to combine the two approaches. By decoupling low-level robotic operations from higher-level decision-making, engineers can develop systems where control software remains predictable and verifiable, while AI components provide flexibility and adaptability. In practice, this means that while core functions like perception, motion control, and sensor integration are implemented as well-tested modules, AI algorithms select and sequence these modules to perform real-world tasks.
This hybrid philosophy minimizes the risks of opaque, purely black-box models by anchoring them in reusable, atomic actions. In doing so, it offers a pathway toward scalable, intelligent, and resilient robotic systems that can benefit from the strengths of both classical engineering and modern AI. A key factor for success is access to reliable and robust software components that can be managed by an AI orchestrator without causing unexpected side effects. In this context, now more than ever, verification and validation represent indispensable requirements. The role of software is to provide a robust foundation that can be configured and utilized by intelligent agents to enable robots that are not only safe and reliable in predictable conditions but also capable of adapting to the uncertainties and complexities of the real world.",Sessions & Discussions,Th2,Thursday 11th,11:15,20,11:35
,William Appleton Coolidge,SDU Software Engineering,,,Robot program structure implications from the use of semantic data,"Ontologies are  useful for modeling multiple dimensions of concerns of a robot in its world. 

When applied, the dimensional coverage of ontologically defined types results in a graph of semantic data instances. 

These graphs of semantic data pervade the system, as the intent is not to lump or reduce the graph at each stage,  but rather to exploit the graph of type instances throughout.

This talk is on the implications of programming with semantic data given the requirements of handling composability,  errors, events, and states. The use of monads is an obvious candidate for structuring computations of semantic data. This talk will discuss the match between semantic data and monads and how to exploit this in robotics.",Sessions & Discussions,Th2,Thursday 11th,11:35,20,11:55
,,,,,,,Lunch,Th.Lu,Thursday 11th,11:55,50,12:45
,Yoganata Kristanto,SDU Software Engineering,,,Visual Representation Techniques for Comprehension of Cobotic Program Execution and Future Reuse,"The growing complexity of High Mix Low Volume (HMLV) manufacturing in Small and Medium Enterprises (SMEs) has increased the need for advanced techniques and methodologies to develop, analyze, and optimize Cobotic programs.  

In this work, we explored the applications of dynamic visualization methods as a means to enhance the understanding of how Cobotic programs execute in run time. By leveraging these visualization techniques, we aimed to provide deeper insights into the interactions between robots and humans during program execution, enabling users to better comprehend the program flow, identify potential issues, and optimize performance for more efficient and effective Cobotic operations. 

These visualizations will also enable users to easily identify and isolate key components of the program, such as specific functions, sequences, or robotic tasks, that can be reused or adapted in future Cobotic programs. By clearly showcasing how different parts of the program interact and contribute to the overall execution, users will be able to recognize reusable parts of the program, streamline the development process, and improve the efficiency and flexibility of designing future Cobotic applications. ",Sessions & Discussions,Th3,Thursday 11th,12:45,20,13:05
,Juan Antonio Pinera Garcia,Gran Sasso Science Institute,,,Adaptation in Heterogeneous Multirobot systems via LLMs,"Uncertainty is an inherent challenge in planning and executing missions within dynamic environments, especially when critical information is incomplete (epistemic uncertainty). Traditional planning methods often assume fixed conditions, rendering them inadequate for scenarios where environmental conditions or operational contexts change unpredictably at runtime. This paper addresses the critical issue of managing uncertainties throughout the entire mission lifecycle by introducing a two-layered adaptive framework. Our proposed solution combines mission specifications featuring adaptable tasks with runtime adaptability enabled by trigger functions. These trigger functions dynamically select suitable adaptation alternatives during mission execution, ensuring resilience in the face of unforeseen events. Furthermore, we integrate large language models (LLMs) for runtime adaptation, leveraging their capability to generate real-time recovery strategies when disruptions occur due to unsatisfied preconditions. Through this novel approach, the system proactively manages epistemic uncertainties and reacts effectively to unpredictable runtime disruptions, significantly enhancing operational robustness and flexibility.",Sessions & Discussions,Th3,Thursday 11th,13:05,20,13:25
,Jude Gyimah,Ruhr University Bochum,,,Quality Aspects of Robot Mission Requirements for Mission Modeling and Synthesis,"Task-performing robots, whether in service or industrial domains, are designed to operate autonomously in environments that may be hazardous or beyond human capabilities. To optimize performance in such robots and ensure alignment with operational objectives, roboticists must interpret and analyze robotic behaviors exhibited. These behaviors are typically formalized as mission specifications, yet diverse industrial roles, priorities, and expertise necessitate interpretable representations tailored to different stakeholder needs. Existing research on mission specification engineering has largely focused on specification modeling techniques, often overlooking the challenge of reverse-engineering quality requirements in the process. This study addresses this gap by introducing a qualitative framework for assessing behavior trees and mission requirements through a structured set of criteria. By intuitively mapping natural language descriptions to machine-executable behavior tree models, our approach enhances the interpretability, understandability, and explainability of robotic missions.",Sessions & Discussions,Th3,Thursday 11th,13:25,20,13:45
,Forough Zamani,Delft University of Technology (TU Delft) Cognitive Robotics Department,,,A Causal Modeling Approach for Self-Tuning the ROS 2 Navigation Stack,"Autonomous navigation system in ROS 2 (Nav2) require careful tuning of multiple interdependent parameters, such as global planners, local controllers, footprint specifications, and costmap settings. Manual tuning of these components is time-consuming and often error-prone due to the complex dependencies among them. This paper proposes a causal modelling approach that allows a robot to discover and leverage the causal structure of its navigation configuration. By learning explicit causal relationships between navigation parameters and performance metrics, the robot can autonomously select or adapt configurations to optimize navigation and reduce collisions. We validate our approach in both simulation and physical robots, demonstrating that incorporating causal insights can improve performance while alleviating the need for extensive manual tuning.",Sessions & Discussions,Th3,Thursday 11th,13:45,20,14:05
,,,,,,,Coffee Break,Th.CB2,Thursday 11th,14:05,15,14:20
,Yorick Sens,Ruhr University Bochum,,,Safeguarding ML-enabled Systems,"Robotic systems increasingly rely on machine learning (ML) for different tasks, such as perception, planning, and decision making. However, the lack of formal guarantees in ML models poses significant challenges for deployment in safety-critical domains, such as cyber physical systems and robotics. Ensuring the reliability and security of these systems at runtime is essential to prevent failures and mitigate risks. In this talk, we will characterize the state-of-the-art and state-of-practice regarding safeguards for ML-enabled systems and outline a research vision for the development of a comprehensive framework for building reliable and secure ML-enabled systems.",Sessions & Discussions,Th4,Thursday 11th,14:20,20,14:40
,Taichi Ishikawa and Takashi Yoshimi,Shibaura Institute of Technology,,,Consideration and verification of a decoration sticker attachment motion to the candle side surface by a robot arm,,Sessions & Discussions,Th4,Thursday 11th,14:40,20,15:00
,Sara Pettinari,Gran Sasso Science Institute,,,Enhancing Robotic Mission Analysis via Process Mining and Visual Analytics,"Robotic systems are increasingly deployed across various domains to automate complex activities, often operating autonomously and interacting with dynamic environments. Understanding and analyzing their mission execution is crucial for optimizing performance, ensuring reliability, and preventing failures. Process mining has emerged as a promising approach to extract meaningful insights from event logs, uncovering behavioral patterns and mission execution flows. However, the vast amounts of low-level data generated by robotic systems pose challenges for effective mission analysis. To address this, integrating process mining with visual analytics provides a powerful solution, combining automated analysis with interactive visualizations to enhance interpretability. 
This talk will discuss the application of process mining and visual analytics to analyze robotic system missions, highlighting current challenges and opportunities.",Sessions & Discussions,Th4,Thursday 11th,15:00,20,15:20
,Mukelabai Mukelabai,Ruhr-University Bochum,,,Data-Driven Fault Localization in Practice: A Survey,"Fault localization is a critical yet challenging aspect of software development, essential for identifying the root causes of failures and enhancing software quality. Despite its significance, fault localization remains a complex, time-consuming task, particularly in modern software systems characterized by expansive codebases and complex component interactions. A primary challenge is efficiently extracting relevant information from runtime data-specifically logs-to accurately trace faults back to faulty code.

While substantial research has been conducted on fault localization techniques, there is a significant gap in understanding how developers actually implement and utilize these techniques in practice, especially in large-scale industrial settings in the automotive domain. Existing studies have focused primarily on theoretical approaches, general software systems, or small-scale evaluations, with limited insight into real-world practices, challenges, and collaborative aspects of fault localization in the automotive industry.

To address this gap, we conducted a comprehensive survey of 68 software developers at an automotive company in Germany to investigate current practices, challenges, and strategies employed for logging, log analysis, and fault localization. Our study examines how developers leverage logs for fault localization, particularly when faults stem from interactions between features or components, and how they coordinate with colleagues during this process.

Key findings reveal that developers spend approximately 22% of their time analyzing logs, primarily for root-cause analysis, with significant variation (5-60%) across teams. Most analysis involves collaboration (67%), often with senior-junior pairings or component experts. Major challenges include log volume and noise (68%), format inconsistency (58%), and lack of context (52%). Our study also highlights the gap between logging implementation and analysis needs, with developers mostly using semi-structured log formats, adhoc-processes for analysis, and relying mostly on informal guidelines. These insights provide valuable direction for improving fault localization tools and practices in industrial software development, particularly in the automotive domain.
",Sessions & Discussions,Th4,Thursday 11th,15:20,20,15:40
,,,,,,,Coffee break,Th.CB3,Thursday 11th,15:40,20,16:00
,Mehran Rostamnia,Gran Sasso Science Institute (GSSI),,,Towards Adaptable and Uncertainty-aware Behavior Trees,"Space robotic missions are taken on a highly uncertain ground, yet require high autonomy. In space, events are unknown and their effects are hard to predict. Mission designers are forced to make decisions despite an inherent lack of information and this results in complex and stiff specifications. Stiffness flags for brittleness. Towards flexibility and modularity, Behavior Trees foster a tractable notation for reactive behavior, attracting the spotlight of robotic mission specifications. However, they lack support for taming uncertainty at runtime. This paper proposes a first step towards the extension of behavior trees with adaptability in order to deal with uncertainty. Our implementation extends the behavior trees constructs with adaptable nodes, i.e., nodes that can be hot-swapped at runtime. Our framework relies on quasi-natural language requirements modeling in FRETISH notation, with transformations to uncertainty-aware behavior trees and deployment to space robotics scenarios in the context of Space ROS. We showcase the use of our framework within the simulation of a NASA mission on Mars.",Sessions & Discussions,Th5,Thursday 11th,16:00,20,16:20
,Mohammad Reza Mousavi,King's College London,,,Assessing Realism of Critical Scenarios in the DMV California Dataset,"With the emergence of autonomous vehicles comes the requirement of adequate
and rigorous testing, particularly in critical scenarios that are both challenging
and potentially hazardous. Generating synthetic critical scenarios in simulation
for testing autonomous vehicles has therefore received considerable interest; yet,
it is unclear how such scenarios relate to the actual crash or near-crash scenarios
involving autonomous vehicles. Consequently, their realism is unknown. In this
paper, we define realism as the degree of similarity of synthetic critical scenarios
to real-world critical scenarios. We propose a methodology to measure realism
using two metrics, namely attribute distribution and Euclidean distance. The
methodology extracts various attributes from synthetic and realistic critical scenario datasets and performs a set of statistical tests to compare their distributions
and distances. As a proof of concept for our methodology, we compare synthetic
collision scenarios from DeepScenario against realistic autonomous vehicle collisions collected by the Department of Motor Vehicles in California, to analyse how
well DeepScenario synthetic collision scenarios are aligned with real autonomous
vehicle collisions recorded scenarios in California. We focus on five key attributes
that are extractable from both datasets, and analyse the attribution distribution
and distance between scenarios in the two datasets. Further, we derive recommendations to improve the realism of synthetic scenarios based on our analysis. Our
study of realism provides a framework that can be replicated and extended for
other dataset both concerning real-world and synthetically-generated scenarios.

Based on the following joint publication with Qunying Song and Avner Bensoussan: 


 Q. Song, A. Bensoussan, and M.R. Mousavi. Synthetic vs. Real: An Analysis of Critical Scenarios for Autonomous Vehicle Testing. Automated Software Engineering Journal, 2025.


",Sessions & Discussions,Th5,Thursday 11th,16:20,20,16:40
,Henriette Knopp,Ruhr-University Bochum,,,On Developing ML-based systems: Thinking Machine Learning on a Software Scale,"The rise of machine learning (ML) has led to the widespread adoption of these technologies in a number of domains, including robotics, which represents one of the most complex forms of applied ML, where multiple models are combined to solve complex tasks such as perception and sensor fusion. However, integrating models into systems, and managing the many different artifacts involved, is far from trivial and still remains an open challenge. 
This talk will summarize results from an empirical study on 3,000 open-source ML-enabled systems. It will discuss findings on the integration of ML-models from that study and ongoing case studies on best practices and patterns for integrating and training ML models in a system context.",Sessions & Discussions,Th5,Thursday 11th,16:40,20,17:00
,,,,,,,Round Table Discussions / Closing Remarks,Th.RT,Thursday 11th,17:00,45,17:45